# WonderQ

This API's skeleton was generated by [generator-rest](https://github.com/diegohaz/generator-rest).

## Setting up

Make sure you have installed all these before starting:

- [Node](https://nodejs.org/en/download/)
- [Yarn](https://yarnpkg.com/en/docs/getting-started)

## Running the project

To run the project, just run these two commands:

```
$ yarn install
$ yarn dev
```

To run the project tests, run this command:

```
$ yarn test
```

The amount of time that WonderQ will wait for message confirmation can be configured on `messageConfirmationWaiting` inside `src/config.js`.

## API docs

| Endpoint            | Description                        | Params                                    | Sample response                                                                                                                                                                                 |
| ------------------- | ---------------------------------- | ----------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `GET /messages`     | Pulls unconsumed messages          | None                                      | `[{"id":1,"body":{"mySampleMessageKey":"Sample value"},"consumedAt":1602532383892},{"id":2,"body":[{"myOtherSampleMessageKey":"Other sample value inside array"}],"consumedAt":1602532383892}]` |
| `POST /messages`    | Inserts a new message on the queue | Body must be a valid JSON object or array | `{"id":1,"body":{"mySampleMessageKey":"Sample value"}`                                                                                                                                          |
| `PUT /messages/:id` | Confirms message was consumed      | `:id` must be a valid message ID          | `{"id":1,"body":{"mySampleMessageKey":"Sample value"},"consumedAt":1602532544925}`                                                                                                              |

## Taking the project to production

In order to take the project to a productive environment, there are a few things that must be taken into account and added to de project:

- **Database persistence:** it would be suitable to store the messages in a database, a non-relational one would be a good choice for this case. MongoDB, Firebase or Redis could be a good fits depending on the specifics (or maybe some of them combined). This also means removing the Mutex and delegating that responsibility to the chosen DB.
- **Environment configuration:** support multiple environments (development, test, production) to take the sensitive information out of the codebase.
- **CI/CD**: develop a CI/CD pipeline to automate the deployment and test execution processes. Some good alternatives are CircleCI or Jenkins.. For a simple and quick setup, and to get something working quickly, CircleCI is a very good option. If something more complex is required, the company seeks to reduce costs and can afford a more time-consuming setup, Jenkins it's a good alternative.
- **Docker container**: a Docker container is a good way to make it easier to build the machine we need to run the project in production.
- **Cloud provider**: The cloud provider must be defined in order to take the project to production (on premise servers don't seem necessary here). While the project and the traffic are small, Heroku its a good option to start with. If the application gets bigger it would be a good idea to migrate to AWS, Google Cloud, or Azure.

## Potential issues

### High traffic

In case of high traffic, we're likely to encounter some issues. Here are some of them and how to address them:

- **High response times**: we're likely to encounter high response times on the GET endpoint, since the requests require mutual exclusion. This means that the response times will increase linearly with the amount of requests.
  _Example_: let's say we have 1000 concurrent requests. The last one will have to wait for the other 999 to finish (or will return timeout). This is avoidable since we already know that the first one will take all the messages and the others will come back empty. So a solution could be to use a fail-fast approach, by looking at the value of the mutex (if the mutex is in use, return an empty array).
- **Overloaded servers**: we may also find that our servers are over-loaded with the amount of requests. This can be solved by adding multiple instances, load balancers or a new interface, like a socket. This last one avoids the constant opening and closing of HTTP connections (but requires users to adapt to the new interface).
